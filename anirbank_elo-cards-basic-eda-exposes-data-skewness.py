import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import seaborn as sns
import matplotlib.pyplot as plt
from numpy import percentile
from datetime import datetime
from scipy.stats import pearsonr
print(os.listdir("../input/elo-merchant-category-recommendation"))
os.list_dir('../input')
# Read historical transactions data
hist_df = pd.read_csv("../input/elo-merchant-category-recommendation/historical_transactions.csv")
hist_df.head()
print(len(hist_df))
hist_df['pur_date']=pd.to_datetime(hist_df['purchase_date'])
hist_df['pur_date'].max()
hist_df['pur_date'].min()
#Lets take last 3 months historical data

date1 = datetime.strptime('2017-12-01', '%Y-%m-%d')
date2 = datetime.strptime('2018-02-28', '%Y-%m-%d')
hist_df_reduced = hist_df.loc[(hist_df['pur_date']>date1) & (hist_df['pur_date']<date2)]
hist_df_reduced.to_csv('hist_DecFeb18.csv')
print(len(hist_df_reduced))
date1 = datetime.strptime('2017-09-01', '%Y-%m-%d')
date2 = datetime.strptime('2017-11-30', '%Y-%m-%d')
hist_df_reduced_SepNov = hist_df.loc[(hist_df['pur_date']>date1) & (hist_df['pur_date']<date2)]
hist_df_reduced_SepNov.to_csv('hist_SepNov.csv')
date1 = datetime.strptime('2017-06-01', '%Y-%m-%d')
date2 = datetime.strptime('2017-08-31', '%Y-%m-%d')
hist_df_reduced_JunAug = hist_df.loc[(hist_df['pur_date']>date1) & (hist_df['pur_date']<date2)]
hist_df_reduced_JunAug.to_csv('hist_JunAug.csv')
date1 = datetime.strptime('2017-03-01', '%Y-%m-%d')
date2 = datetime.strptime('2017-05-31', '%Y-%m-%d')
hist_df_reduced_MarMay = hist_df.loc[(hist_df['pur_date']>date1) & (hist_df['pur_date']<date2)]
hist_df_reduced_MarMay.to_csv('hist_MarMay.csv')
hist_df_reduced_MarMay.head()
date1 = datetime.strptime('2017-01-01', '%Y-%m-%d')
date2 = datetime.strptime('2017-02-28', '%Y-%m-%d')
hist_df_reduced_JanFeb = hist_df.loc[(hist_df['pur_date']>date1) & (hist_df['pur_date']<date2)]
hist_df_reduced_JanFeb.to_csv('hist_JanFeb.csv')
hist_df_reduced['month']=hist_df_reduced['pur_date'].dt.to_period('M')
#Lets see the trans vol by month and week
#hist_df_red_by_month=hist_df_reduced.groupby(['month']).size()
#hist_df_red_by_month.head()
#hist_df_reduced['week']=hist_df_reduced['pur_date'].dt.to_period('W')
#hist_df_red_by_wk=hist_df_reduced.groupby(['week']).size()
#ax = hist_df_red_by_month.plot(kind='bar',figsize=(14,8),fontsize=14)
#ax.set_title("Historical Card Trans Volume By Month",fontsize=28,fontweight='bold')
#ax.set_xlabel("Month",fontsize=14,fontweight='bold')
#ax.set_ylabel("Volume of Trans", fontsize="14",fontweight="bold")
#ax.tick_params(axis='both',which='major',labelsize=18)
#ax.tick_params(axis='both',which='minor',labelsize=18)
#Lets look at the transactions by Merchant Category
Trans_by_MerchantCat = pd.DataFrame(hist_df_reduced.groupby(['merchant_category_id']).size())
Trans_by_MerchantCat = Trans_by_MerchantCat.rename(columns={0: 'TransCt'})
print("Max of Count of Trans by Merch Cat ID:"+str(Trans_by_MerchantCat['TransCt'].max().round(2)))
print("Median of Count of Trans by Merch Cat ID:"+str(round(Trans_by_MerchantCat['TransCt'].median(),2)))
print("Mean of Count of Trans by Merch Cat ID:"+str(round(Trans_by_MerchantCat['TransCt'].mean(),2)))
print("Min of Count of Trans by Merch Cat ID:"+str(round(Trans_by_MerchantCat['TransCt'].min(),2)))
Trans_by_MerchantCat.sort_values(by='TransCt',ascending=False).head()
axarr = Trans_by_MerchantCat['TransCt'].sort_values().plot(kind='bar',figsize=(60,40))
axarr.set_title("Bar chart of count of Trans by Merch Cat Id",fontsize=72,fontweight='bold')
axarr.set_xlabel("Merch Cat Id",fontsize=36)
#axarr[0][0].set_xlim((0,100))
axarr.set_ylabel("Frequency",fontsize=36)
axarr.tick_params(axis='both',which='major',labelsize=36)
axarr.tick_params(axis='both',which='minor',labelsize=36)
TransAmt_by_MerchantCat = pd.DataFrame(hist_df_reduced.groupby(['merchant_category_id'])['purchase_amount'].sum())
TransAmt_by_MerchantCat.head()
print(round(TransAmt_by_MerchantCat['purchase_amount'].max(),2))
print(round(TransAmt_by_MerchantCat['purchase_amount'].min(),2))
print(round(TransAmt_by_MerchantCat['purchase_amount'].median(),2))
axarr = TransAmt_by_MerchantCat['purchase_amount'].sort_values().plot(kind='bar',figsize=(40,40))
axarr.set_title("Bar chart of Amount of Trans by Merch Cat Id",fontsize=72,fontweight='bold')
axarr.set_xlabel("Merch Cat Id",fontsize=36)
#axarr[0][0].set_xlim((0,100))
axarr.set_ylabel("Frequency",fontsize=36)
axarr.tick_params(axis='both',which='major',labelsize=36)
axarr.tick_params(axis='both',which='minor',labelsize=36)
TransAmt_by_Card = pd.DataFrame(hist_df_reduced.groupby(['card_id'])['purchase_amount'].sum())
ax=plt.hist(TransAmt_by_Card['purchase_amount'],bins=5)
plt.xlim(-2000,150000)
plt.show()
print("Max amt by Card:"+str(TransAmt_by_Card.max().round(2)))
print("Min amt by Card:"+str(TransAmt_by_Card.min().round(2)))
print("Median amt by Card:"+str(TransAmt_by_Card.median().round(2)))
data = TransAmt_by_Card['purchase_amount']
percentiles = percentile(data,[10,25,30,50,75,90, 95, 98, 99, 99.95])
print(percentiles.round(2))
print(len(TransAmt_by_Card))
TransAmt_by_Card.sort_values(by='purchase_amount',ascending=False)[:50]
TransAmt_by_Card.sort_values(by='purchase_amount',ascending=False)[27000:27100]
TransAmt_by_Card_red = TransAmt_by_Card.loc[(TransAmt_by_Card['purchase_amount']>=100)]
print(len(TransAmt_by_Card_red))
ax=plt.hist(TransAmt_by_Card_red['purchase_amount'],bins=100)
plt.xlim(-2000,25000)
plt.show()
TransAmt_by_CardbyMerch = pd.DataFrame(hist_df_reduced.groupby(['card_id','merchant_id'])['purchase_amount'].sum())
data = TransAmt_by_CardbyMerch['purchase_amount']
percentiles = percentile(data,[10,25,30,50,75,90, 95, 98, 99, 99.95])
print(percentiles.round(2))
TransVol_by_CardbyMerch = pd.DataFrame(hist_df_reduced.groupby(['card_id','merchant_id']).size())
data = TransVol_by_CardbyMerch
percentiles = percentile(data,[10,25,30,50,75,90, 95, 98, 99, 99.95])
print(percentiles)
print(len(TransVol_by_CardbyMerch))
data = Trans_by_MerchantCat['TransCt']
percentiles = percentile(data,[10,25,30,50,75,90])
print(percentiles.round())
Trans_by_MerchantCat_gt25k=Trans_by_MerchantCat['TransCt'].loc[(Trans_by_MerchantCat['TransCt'] > 25000)]
len(Trans_by_MerchantCat)
len(Trans_by_MerchantCat_gt25k)
axarr = Trans_by_MerchantCat_gt25k.sort_values().plot(kind='bar',figsize=(60,40))
axarr.set_title("Bar chart of count of Trans by Merch Cat Id (>25k)",fontsize=72,fontweight='bold')
axarr.set_xlabel("Merch Cat Id",fontsize=36)
#axarr[0][0].set_xlim((0,100))
axarr.set_ylabel("Frequency",fontsize=36)
axarr.tick_params(axis='both',which='major',labelsize=36)
axarr.tick_params(axis='both',which='minor',labelsize=36)
HighVolMerchCat = Trans_by_MerchantCat_gt25k.index
HighVolMerchCat
#read train df
train_df=pd.read_csv('../input/elo-merchant-category-recommendation/train.csv')
train_df.head()
print(len(train_df))
train_df['first_active_month']=pd.to_datetime(train_df['first_active_month'])
train_df['first_active_month'].min()
train_df['first_active_month'].max()
print(len(train_df['card_id'].unique()))
train_df['month']=train_df['first_active_month'].dt.to_period('M')
train_df_by_month=train_df.groupby(['month']).size()
ax = train_df_by_month.plot(kind='bar',figsize=(14,8),fontsize=14)
ax.set_title("Training dataset - Card Trans Volume By First Active Month",fontsize=28,fontweight='bold')
ax.set_xlabel("First Active Month",fontsize=14,fontweight='bold')
ax.set_ylabel("Volume of Trans", fontsize="14",fontweight="bold")
ax.tick_params(axis='both',which='major',labelsize=18)
ax.tick_params(axis='both',which='minor',labelsize=18)
print(len(train_df['month'].unique()))
#train_df_by_month_mod = train_df_by_month.loc[train_df_by_month > 250]
#first_act_mth_list = train_df_by_month_mod.index
#first_act_mth_list
#train_df_red = train_df.loc[train_df.month.isin(first_act_mth_list)]
#print(len(train_df_red))
#train_df_red.head()
new_merch_df = pd.read_csv("../input/elo-merchant-category-recommendation/new_merchant_transactions.csv")
new_merch_df.head()
new_merch_df['pur_date']=pd.to_datetime(new_merch_df['purchase_date'])
new_merch_df['pur_date'].max()
new_merch_df['pur_date'].min()
new_merch_df['month']=new_merch_df['pur_date'].dt.to_period('M')
#new_merch_df['wk']=new_merch_df['pur_date'].dt.to_period('W')
new_merch_df_by_month = new_merch_df.groupby(['month']).size()
#new_merch_df_by_wk = new_merch_df.groupby(['wk']).size()
ax = new_merch_df_by_month.plot(kind='bar',figsize=(14,8),fontsize=14)
ax.set_title("New Merchant Card Trans Volume By Month",fontsize=28,fontweight='bold')
ax.set_xlabel("Month",fontsize=14,fontweight='bold')
ax.set_ylabel("Volume of Trans", fontsize="14",fontweight="bold")
ax.tick_params(axis='both',which='major',labelsize=18)
ax.tick_params(axis='both',which='minor',labelsize=18)
#Group by Merchant Category Id
Trans_by_MerchantCat_new = pd.DataFrame(new_merch_df.groupby(['merchant_category_id']).size())
Trans_by_MerchantCat_new = Trans_by_MerchantCat_new.rename(columns={0: 'TransCt'})
axarr = Trans_by_MerchantCat_new['TransCt'].sort_values().plot(kind='bar',figsize=(60,40))
axarr.set_title("New Merchant Count of Trans by Merch Cat Id",fontsize=72,fontweight='bold')
axarr.set_xlabel("Merch Cat Id",fontsize=36)
#axarr[0][0].set_xlim((0,100))
axarr.set_ylabel("Frequency",fontsize=36)
axarr.tick_params(axis='both',which='major',labelsize=36)
axarr.tick_params(axis='both',which='minor',labelsize=36)
data = Trans_by_MerchantCat_new['TransCt']
percentiles = percentile(data,[25,30,50,75,90])
print(percentiles)
Trans_by_MerchantCat_new_gt5k=Trans_by_MerchantCat_new['TransCt'].loc[(Trans_by_MerchantCat_new['TransCt'] > 5000)]
HighVolMerchCat_new = Trans_by_MerchantCat_new_gt5k.index
HighVolMerchCat_new
c = set(HighVolMerchCat) & set(HighVolMerchCat_new)  #  & calculates the intersection.
print(len(c))
HighVolMerchComb = set(HighVolMerchCat) | set(HighVolMerchCat_new)
print(len(HighVolMerchComb))
#new_merch_df_red = new_merch_df.loc[(new_merch_df.merchant_category_id.isin(HighVolMerchCat_new))]
#print(len(new_merch_df_red))
print(len(new_merch_df['card_id'].unique()))
TransAmt_by_CardnewMerch = pd.DataFrame(new_merch_df.groupby(['card_id','merchant_id'])['purchase_amount'].sum())
#TransAmt_by_CardnewMerch.hist()
ax=plt.hist(TransAmt_by_CardnewMerch['purchase_amount'],bins=50)
plt.xlim(-5,25)
plt.show()
data = TransAmt_by_CardnewMerch['purchase_amount']
percentiles = percentile(data,[10,25,30,50,75,90, 95, 98, 99, 99.95])
print(TransAmt_by_CardnewMerch['purchase_amount'].min())
print(TransAmt_by_CardnewMerch['purchase_amount'].max())
print(percentiles)
TransVol_by_CardnewMerch = pd.DataFrame(new_merch_df.groupby(['card_id','merchant_id']).size())
TransVol_by_CardnewMerch = TransVol_by_CardnewMerch.rename(columns={0: 'TransCt'})
TransVol_by_CardnewMerch.sort_values(by='TransCt',ascending=False).head()
TransVol_by_CardnewMerch = TransVol_by_CardnewMerch.reset_index()
TransVol_by_CardnewMerch.head()
data = TransVol_by_CardnewMerch['TransCt']
percentiles = percentile(data,[10,25,30,50,75,90, 95, 98, 99, 99.95,99.98])
print(TransVol_by_CardnewMerch['TransCt'][0].min())
print(TransVol_by_CardnewMerch['TransCt'][0].max())
print(percentiles)
merchant_df = pd.read_csv('../input/elo-merchant-category-recommendation/merchants.csv')
len(merchant_df)
len(merchant_df['merchant_id'].unique())
merchantList=merchant_df['merchant_id'].unique()
merchant_df=merchant_df.drop_duplicates(subset=['merchant_id'])
len(merchant_df)
len(merchant_df['merchant_id'].unique())
merchant_df= merchant_df.reset_index(drop=True)
TransVol_by_CardnewMerch = pd.merge(TransVol_by_CardnewMerch, merchant_df, how = 'inner', left_on = ['merchant_id'], right_on=['merchant_id'])
TransVol_by_CardnewMerch.head()
TransVol_by_CardnewMerchHighVol = TransVol_by_CardnewMerch.loc[(TransVol_by_CardnewMerch.merchant_category_id.isin(HighVolMerchCat_new))]
len(TransVol_by_CardnewMerch)
len(TransVol_by_CardnewMerchHighVol)
TransVol_by_CardnewHighVolMerch=TransVol_by_CardnewMerchHighVol.groupby(['card_id']).size()
TransVol_by_CardnewHighVolMerch.head()
TransVol_by_CardnewHighVolMerch=pd.DataFrame(TransVol_by_CardnewHighVolMerch)
TransVol_by_CardnewHighVolMerch = TransVol_by_CardnewHighVolMerch.reset_index()
TransVol_by_CardnewHighVolMerch.head()
TransVol_by_CardnewHighVolMerch = TransVol_by_CardnewHighVolMerch.rename(columns={0: 'TransCt'})
TransVol_by_CardnewHighVolMerch.sort_values(by='TransCt',ascending=False).head()
TransVol_by_CardnewHighVolMerch = TransVol_by_CardnewHighVolMerch.rename(columns={'TransCt': 'NewHighVolMerchTransCt'})
TransVol_by_CardnewHighVolMerch.sort_values(by='NewHighVolMerchTransCt',ascending=False).head()
TransVol_by_CardnewMerchCt=TransVol_by_CardnewMerch.groupby(['card_id']).size()
TransVol_by_CardnewMerchCt.sort_values(ascending=False).head()
print(TransVol_by_CardnewMerchCt.min())
print(TransVol_by_CardnewMerchCt.median())
print(TransVol_by_CardnewMerchCt.max())
TransVol_by_CardnewMerchCt = TransVol_by_CardnewMerchCt.reset_index()
TransVol_by_CardnewMerchCt = TransVol_by_CardnewMerchCt.rename(columns={0: 'NewMerchTransCt'})
TransVol_by_CardnewMerchCt.head()
#hist_df_reduced_merch = hist_df_reduced.loc[(hist_df_reduced.merchant_category_id.isin(HighVolMerchCat))]
#print(len(hist_df_reduced_merch))
#print(len(hist_df_reduced_merch['card_id'].unique()))
#hist_df_reduced_merch.head()
print(len(hist_df_reduced['city_id'].unique()))
#Lets group transactions by city
hist_df_by_city = hist_df_reduced.groupby(['city_id']).size()
print(hist_df_by_city.max())
print(hist_df_by_city.min())
print(hist_df_by_city.median())
axarr = hist_df_by_city.sort_values().plot(kind='bar',figsize=(60,40))
axarr.set_title("Bar chart of count of Trans by City Id",fontsize=72,fontweight='bold')
axarr.set_xlabel("City Id",fontsize=36)
#axarr[0][0].set_xlim((0,100))
axarr.set_ylabel("Frequency",fontsize=36)
axarr.tick_params(axis='both',which='major',labelsize=36)
axarr.tick_params(axis='both',which='minor',labelsize=36)
data = hist_df_by_city
percentiles = percentile(data, [10,25,30,40, 50, 60, 75, 90])
print(percentiles)
#hist_df_by_city=hist_df_by_city.loc[(hist_df_by_city>15000)]
#city_list = hist_df_by_city.index
#hist_df_reduced_merch_city = hist_df_reduced_merch.loc[hist_df_reduced_merch.city_id.isin(city_list)]
#print(len(hist_df_reduced_merch_city))
new_merch_df_city = new_merch_df.groupby(['city_id']).size()
data = new_merch_df_city
percentiles = percentile(data, [10,25,30,40, 50, 60, 75, 90])
print(percentiles)
axarr = new_merch_df_city.sort_values().plot(kind='bar',figsize=(60,40))
axarr.set_title("Bar chart of count of Trans by City Id, New Merch",fontsize=72,fontweight='bold')
axarr.set_xlabel("City Id",fontsize=36)
#axarr[0][0].set_xlim((0,100))
axarr.set_ylabel("Frequency",fontsize=36)
axarr.tick_params(axis='both',which='major',labelsize=36)
axarr.tick_params(axis='both',which='minor',labelsize=36)
#new_merch_df_city=new_merch_df_city.loc[(new_merch_df_city>5000)]
#city_list_new = new_merch_df_city.index
#new_merch_df_city = new_merch_df_red.loc[new_merch_df_red.city_id.isin(city_list_new)]
#new_merch_df_city.head()
#en(new_merch_df_city)
new_merch_trans_sum_bycard = new_merch_df.groupby(['card_id'])['purchase_amount'].sum()
new_merch_trans_max_bycard = new_merch_df.groupby(['card_id'])['purchase_amount'].max()
new_merch_trans_median_bycard = new_merch_df.groupby(['card_id'])['purchase_amount'].median()
new_merch_trans_std_bycard = new_merch_df.groupby(['card_id'])['purchase_amount'].std()
new_merch_trans_sum_bycard.sort_values(ascending=False).head()
hist_trans_sum_bycard = hist_df_reduced.groupby(['card_id'])['purchase_amount'].sum()
hist_trans_max_bycard = hist_df_reduced.groupby(['card_id'])['purchase_amount'].max()
hist_trans_median_bycard = hist_df_reduced.groupby(['card_id'])['purchase_amount'].median()
hist_trans_std_bycard = hist_df_reduced.groupby(['card_id'])['purchase_amount'].std()
hist_trans_sum_bycard.sort_values(ascending=False).head()
Card_union = set(new_merch_trans_sum_bycard.index) | set(hist_trans_sum_bycard.index)
len(Card_union)
Card_intersection = set(new_merch_trans_sum_bycard.index) & set(hist_trans_sum_bycard.index)
len(Card_intersection)
#new_merch_df_city.to_csv('new_merch_red.csv')
#hist_df_reduced_merch_city.to_csv('hist_trans_red.csv')
#train_df_red.to_csv('train_red.csv')
hist_df_reduced.head()
hist_df_auth_ct_bycard=hist_df_reduced.groupby('card_id')['authorized_flag'].apply(lambda x: (x=='Y').sum()).reset_index(name='Auth_count')
hist_df_auth_ct_bycard.head()
hist_df_ref_ct_bycard=hist_df_reduced.groupby('card_id')['authorized_flag'].apply(lambda x: (x=='N').sum()).reset_index(name='Ref_count')
hist_df_ref_ct_bycard.head()
print(len(hist_trans_sum_bycard.index))
print(len(new_merch_trans_sum_bycard.index))
#df_card_all = pd.concat([new_merch_trans_sum_bycard, hist_trans_sum_bycard])\
#       .groupby('card_id').sum().reset_index()

#df_card_all.head()
#print(len(df_card_all))
new_merch_trans_max_bycard = pd.DataFrame(new_merch_trans_max_bycard)
new_merch_trans_median_bycard = pd.DataFrame(new_merch_trans_median_bycard)
new_merch_trans_std_bycard = pd.DataFrame(new_merch_trans_std_bycard)
#new_merch_trans_max_bycard.head()
hist_trans_max_bycard = pd.DataFrame(hist_trans_max_bycard)
hist_trans_median_bycard = pd.DataFrame(hist_trans_median_bycard)
hist_trans_std_bycard = pd.DataFrame(hist_trans_std_bycard)
new_merch_trans_max_bycard = new_merch_trans_max_bycard.rename(columns={'purchase_amount': 'NewMerch_Max_Amt'})
new_merch_trans_median_bycard = new_merch_trans_median_bycard.rename(columns={'purchase_amount': 'NewMerch_Median_Amt'})
new_merch_trans_std_bycard = new_merch_trans_std_bycard.rename(columns={'purchase_amount': 'NewMerch_StdDev_Amt'})
hist_trans_max_bycard = hist_trans_max_bycard.rename(columns={'purchase_amount': 'HistMerch_Max_Amt'})
hist_trans_median_bycard = hist_trans_median_bycard.rename(columns={'purchase_amount': 'HistMerch_Median_Amt'})
hist_trans_std_bycard = hist_trans_std_bycard.rename(columns={'purchase_amount': 'HistMerch_StdDev_Amt'})
#hist_instalment_by_card = hist_df_reduced.groupby(['card_id'])['installments'].sum()
#new_instalment_by_card = new_merch_df.groupby(['card_id'])['installments'].sum()
#df_card_all_instalment = pd.concat([hist_instalment_by_card, new_instalment_by_card])\
#       .groupby('card_id').sum().reset_index()
#df_card_all_instalment.head()
#train_df_merged = pd.merge(train_df,df_card_all, how = 'inner', left_on = ['card_id'], right_on=['card_id'])
#train_df_merged = pd.merge(train_df_merged,df_card_all_instalment, how = 'inner', left_on = ['card_id'], right_on=['card_id'])
train_df_merged = pd.merge(train_df,new_merch_trans_max_bycard, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])

train_df_merged = pd.merge(train_df_merged,TransVol_by_CardnewHighVolMerch, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])
train_df_merged = pd.merge(train_df_merged,TransVol_by_CardnewMerchCt, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])
#train_df_merged = pd.merge(train_df_merged,new_merch_trans_median_bycard, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])
#train_df_merged = pd.merge(train_df_merged,new_merch_trans_std_bycard, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])
train_df_merged.head()
#train_df_merged = pd.merge(train_df_merged,hist_trans_max_bycard, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])
#train_df_merged = pd.merge(train_df_merged,hist_trans_median_bycard, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])
#train_df_merged = pd.merge(train_df_merged,hist_trans_std_bycard, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])
train_df_merged.head()
#train_df_merged = pd.merge(train_df_merged,TransVol_by_CardMerchm, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])
train_df_merged = pd.merge(train_df_merged,hist_df_auth_ct_bycard, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])

train_df_merged = pd.merge(train_df_merged,hist_df_ref_ct_bycard, how = 'inner', left_on = ['card_id'], right_on = ['card_id'])
train_df_merged.head()
#train_df_merged.to_csv('train_df_merged.csv')
#do some data cleansing to make sure the correlation analysis runs without any error
#m=train_df_merged["NewMerch_StdDev_Amt"].isnull().any()
#print(m[m])
#m=train_df_merged["HistMerch_StdDev_Amt"].isnull().any()
#print(m[m])

#train_df_merged["NewMerch_StdDev_Amt"].fillna(train_df_merged["NewMerch_StdDev_Amt"].mean())
#train_df_merged["NewMerch_StdDev_Amt"] = train_df_merged["NewMerch_StdDev_Amt"].apply(lambda x: x if not pd.isnull(x) else train_df_merged["NewMerch_StdDev_Amt"].mean())
#m=train_df_merged["NewMerch_StdDev_Amt"].isnull().any()
#print(m[m])
#train_df_merged["HistMerch_StdDev_Amt"].fillna(train_df_merged["HistMerch_StdDev_Amt"].mean())
#train_df_merged["HistMerch_StdDev_Amt"] = train_df_merged["HistMerch_StdDev_Amt"].apply(lambda x: x if not pd.isnull(x) else train_df_merged["NewMerch_StdDev_Amt"].mean())
#m=train_df_merged["HistMerch_StdDev_Amt"].isnull().any()
#print(m[m])
#
#corr, _ = pearsonr(train_df_merged['target'],train_df_merged['installments'])
#print('Pearsons correlation betweeen target and installments: %.3f' % corr)
#corr, _ = pearsonr(train_df_merged['target'],train_df_merged['purchase_amount'])
#print('Pearsons correlation betweeen target and sum purchase amount by card id: %.3f' % corr)
corr, _ = pearsonr(train_df_merged['target'],train_df_merged['NewMerch_Max_Amt'])
print('Pearsons correlation betweeen target and New Merch Max puch amt: %.3f' % corr)
corr, _ = pearsonr(train_df_merged['target'],train_df_merged['NewMerchTransCt'])
print('Pearsons correlation betweeen target and New Merch Count: %.3f' % corr)
corr, _ = pearsonr(train_df_merged['target'],train_df_merged['NewHighVolMerchTransCt'])
print('Pearsons correlation betweeen target and New Merch Count: %.3f' % corr)
corr, _ = pearsonr(train_df_merged['target'],train_df_merged['Auth_count'])
print('Pearsons correlation betweeen target and Authorised Trans Count: %.3f' % corr)
corr, _ = pearsonr(train_df_merged['target'],train_df_merged['Ref_count'])
print('Pearsons correlation betweeen target and Refused Trans Count: %.3f' % corr)
train_df_merged['feature_1'].value_counts().sort_values().plot(kind='bar')
train_df_merged['feature_2'].value_counts().sort_values().plot(kind='bar')
train_df_merged['feature_3'].value_counts().sort_values().plot(kind='bar')
train_df_corr = train_df_merged[['NewMerch_Max_Amt','NewMerchTransCt','NewHighVolMerchTransCt','Auth_count','Ref_count','target']]

corr=train_df_corr.corr()
corr
# Generate a mask for the upper triangle
mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True
# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))
# Generate a custom diverging colormap
cmap = sns.diverging_palette(220, 10, as_cmap=True)
# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})
plt.show()
import seaborn as sns
sns.set(style="ticks")
sns.pairplot(train_df_merged[['target','feature_1']])
import seaborn as sns
sns.set(style="ticks")
sns.pairplot(train_df_merged[['target','feature_2']])
import seaborn as sns
sns.set(style="ticks")
sns.pairplot(train_df_merged[['target','feature_3']])
train_df_merged['target'].hist()
ax=plt.hist(train_df_merged['target'],bins=100)
plt.xlim(-7.5,7.5)
plt.show()
print(len(train_df_merged.loc[(train_df_merged['target'] < -7)]))
print(len(train_df_merged.loc[(train_df_merged['target'] > 7)]))
print(len(train_df_merged))
train_df_merged = train_df_merged.loc[(train_df_merged['target'] >= -7)]
print(len(train_df_merged))
train_df_merged = train_df_merged.loc[(train_df_merged['target'] <= 7)]
train_df_merged.to_csv('train_df_merged.csv')
print(len(train_df_merged))
train_df_corr = train_df_merged[['NewMerch_Max_Amt','NewMerchTransCt','NewHighVolMerchTransCt','Auth_count','Ref_count','target']]

corr=train_df_corr.corr()
corr
# Generate a mask for the upper triangle
mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True
# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))
# Generate a custom diverging colormap
cmap = sns.diverging_palette(220, 10, as_cmap=True)
# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": .5})
plt.show()
#merchant_df = pd.read_csv('../input/merchants.csv')
merchant_df.head()
print(len(merchant_df['merchant_id'].unique()))
print(len(merchant_df['merchant_group_id'].unique()))
print(len(merchant_df['merchant_category_id'].unique()))
merchant_df['subsector_id'].value_counts()
merchant_df['category_1'].value_counts()
merchant_df['most_recent_purchases_range'].value_counts()
merchant_df['most_recent_sales_range'].value_counts()