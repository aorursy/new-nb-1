# Making necessary imports

import numpy as np

import pandas as pd

import os

import matplotlib.pyplot as plt


from math import sin, cos, pi

import cv2

from tqdm.notebook import tqdm



from keras.layers.advanced_activations import LeakyReLU

from keras.models import Sequential, Model, load_model

from keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D

from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint

from keras.optimizers import Adam
horizontal_flip = False

rotation_augmentation = True

brightness_augmentation = True

shift_augmentation = True

random_noise_augmentation = True



include_unclean_data = True    # Whether to include samples with missing keypoint values. Note that the missing values would however be filled using Pandas' 'ffill' later.

sample_image_index = 20    # Index of sample train image used for visualizing various augmentations



rotation_angles = [12]    # Rotation angle in degrees (includes both clockwise & anti-clockwise rotations)

pixel_shifts = [12]    # Horizontal & vertical shift amount in pixels (includes shift from all 4 corners)



NUM_EPOCHS = 100

BATCH_SIZE = 128
print("Contents of input/facial-keypoints-detection directory: ")




print("\nExtracting .zip dataset files to working directory ...")





print("\nCurrent working directory:")


print("\nContents of working directory:")




train_file = 'training.csv'

test_file = 'test.csv'

idlookup_file = '../input/facial-keypoints-detection/IdLookupTable.csv'

train_data = pd.read_csv(train_file)

test_data = pd.read_csv(test_file)

idlookup_data = pd.read_csv(idlookup_file)
def plot_sample(image, keypoint, axis, title):

    image = image.reshape(96,96)

    axis.imshow(image, cmap='gray')

    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)

    plt.title(title)
train_data.head().T
test_data.head()
idlookup_data.head().T
print("Length of train data: {}".format(len(train_data)))

print("Number of Images with missing pixel values: {}".format(len(train_data) - int(train_data.Image.apply(lambda x: len(x.split())).value_counts().values)))
train_data.isnull().sum()



clean_train_data = train_data.dropna()

print("clean_train_data shape: {}".format(np.shape(clean_train_data)))



# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html

unclean_train_data = train_data.fillna(method = 'ffill')

print("unclean_train_data shape: {}\n".format(np.shape(unclean_train_data)))



def load_images(image_data):

    images = []

    for idx, sample in image_data.iterrows():

        image = np.array(sample['Image'].split(' '), dtype=int)

        image = np.reshape(image, (96,96,1))

        images.append(image)

    images = np.array(images)/255.

    return images



def load_keypoints(keypoint_data):

    keypoint_data = keypoint_data.drop('Image',axis = 1)

    keypoint_features = []

    for idx, sample_keypoints in keypoint_data.iterrows():

        keypoint_features.append(sample_keypoints)

    keypoint_features = np.array(keypoint_features, dtype = 'float')

    return keypoint_features



clean_train_images = load_images(clean_train_data)

print("Shape of clean_train_images: {}".format(np.shape(clean_train_images)))

clean_train_keypoints = load_keypoints(clean_train_data)

print("Shape of clean_train_keypoints: {}".format(np.shape(clean_train_keypoints)))

test_images = load_images(test_data)

print("Shape of test_images: {}".format(np.shape(test_images)))



train_images = clean_train_images

train_keypoints = clean_train_keypoints

fig, axis = plt.subplots()

plot_sample(clean_train_images[sample_image_index], clean_train_keypoints[sample_image_index], axis, "Sample image & keypoints")



if include_unclean_data:

    unclean_train_images = load_images(unclean_train_data)

    print("Shape of unclean_train_images: {}".format(np.shape(unclean_train_images)))

    unclean_train_keypoints = load_keypoints(unclean_train_data)

    print("Shape of unclean_train_keypoints: {}\n".format(np.shape(unclean_train_keypoints)))

    train_images = np.concatenate((train_images, unclean_train_images))

    train_keypoints = np.concatenate((train_keypoints, unclean_train_keypoints))
def left_right_flip(images, keypoints):

    flipped_keypoints = []

    flipped_images = np.flip(images, axis=2)   # Flip column-wise (axis=2)

    for idx, sample_keypoints in enumerate(keypoints):

        flipped_keypoints.append([96.-coor if idx%2==0 else coor for idx,coor in enumerate(sample_keypoints)])    # Subtract only X co-ordinates of keypoints from 96 for horizontal flipping

    return flipped_images, flipped_keypoints



if horizontal_flip:

    flipped_train_images, flipped_train_keypoints = left_right_flip(clean_train_images, clean_train_keypoints)

    print("Shape of flipped_train_images: {}".format(np.shape(flipped_train_images)))

    print("Shape of flipped_train_keypoints: {}".format(np.shape(flipped_train_keypoints)))

    train_images = np.concatenate((train_images, flipped_train_images))

    train_keypoints = np.concatenate((train_keypoints, flipped_train_keypoints))

    fig, axis = plt.subplots()

    plot_sample(flipped_train_images[sample_image_index], flipped_train_keypoints[sample_image_index], axis, "Horizontally Flipped") 
def rotate_augmentation(images, keypoints):

    rotated_images = []

    rotated_keypoints = []

    print("Augmenting for angles (in degrees): ")

    for angle in rotation_angles:    # Rotation augmentation for a list of angle values

        for angle in [angle,-angle]:

            print(f'{angle}', end='  ')

            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)

            angle_rad = -angle*pi/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)

            # For train_images

            for image in images:

                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)

                rotated_images.append(rotated_image)

            # For train_keypoints

            for keypoint in keypoints:

                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension

                for idx in range(0,len(rotated_keypoint),2):

                    # https://in.mathworks.com/matlabcentral/answers/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point

                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)

                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)

                rotated_keypoint += 48.   # Add the earlier subtracted value

                rotated_keypoints.append(rotated_keypoint)

            

    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints



if rotation_augmentation:

    rotated_train_images, rotated_train_keypoints = rotate_augmentation(clean_train_images, clean_train_keypoints)

    print("\nShape of rotated_train_images: {}".format(np.shape(rotated_train_images)))

    print("Shape of rotated_train_keypoints: {}\n".format(np.shape(rotated_train_keypoints)))

    train_images = np.concatenate((train_images, rotated_train_images))

    train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))

    fig, axis = plt.subplots()

    plot_sample(rotated_train_images[sample_image_index], rotated_train_keypoints[sample_image_index], axis, "Rotation Augmentation")
def alter_brightness(images, keypoints):

    altered_brightness_images = []

    inc_brightness_images = np.clip(images*1.2, 0.0, 1.0)    # Increased brightness by a factor of 1.2 & clip any values outside the range of [-1,1]

    dec_brightness_images = np.clip(images*0.6, 0.0, 1.0)    # Decreased brightness by a factor of 0.6 & clip any values outside the range of [-1,1]

    altered_brightness_images.extend(inc_brightness_images)

    altered_brightness_images.extend(dec_brightness_images)

    return altered_brightness_images, np.concatenate((keypoints, keypoints))



if brightness_augmentation:

    altered_brightness_train_images, altered_brightness_train_keypoints = alter_brightness(clean_train_images, clean_train_keypoints)

    print(f"Shape of altered_brightness_train_images: {np.shape(altered_brightness_train_images)}")

    print(f"Shape of altered_brightness_train_keypoints: {np.shape(altered_brightness_train_keypoints)}")

    train_images = np.concatenate((train_images, altered_brightness_train_images))

    train_keypoints = np.concatenate((train_keypoints, altered_brightness_train_keypoints))

    fig, axis = plt.subplots()

    plot_sample(altered_brightness_train_images[sample_image_index], altered_brightness_train_keypoints[sample_image_index], axis, "Increased Brightness") 

    fig, axis = plt.subplots()

    plot_sample(altered_brightness_train_images[len(altered_brightness_train_images)//2+sample_image_index], altered_brightness_train_keypoints[len(altered_brightness_train_images)//2+sample_image_index], axis, "Decreased Brightness") 
def shift_images(images, keypoints):

    shifted_images = []

    shifted_keypoints = []

    for shift in pixel_shifts:    # Augmenting over several pixel shift values

        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:

            M = np.float32([[1,0,shift_x],[0,1,shift_y]])

            for image, keypoint in zip(images, keypoints):

                shifted_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)

                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])

                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):

                    shifted_images.append(shifted_image.reshape(96,96,1))

                    shifted_keypoints.append(shifted_keypoint)

    shifted_keypoints = np.clip(shifted_keypoints,0.0,96.0)

    return shifted_images, shifted_keypoints



if shift_augmentation:

    shifted_train_images, shifted_train_keypoints = shift_images(clean_train_images, clean_train_keypoints)

    print(f"Shape of shifted_train_images: {np.shape(shifted_train_images)}")

    print(f"Shape of shifted_train_keypoints: {np.shape(shifted_train_keypoints)}")

    train_images = np.concatenate((train_images, shifted_train_images))

    train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))

    fig, axis = plt.subplots()

    plot_sample(shifted_train_images[sample_image_index], shifted_train_keypoints[sample_image_index], axis, "Shift Augmentation")
def add_noise(images):

    noisy_images = []

    for image in images:

        noisy_image = cv2.add(image, 0.008*np.random.randn(96,96,1))    # Adding random normal noise to the input image & clip the resulting noisy image between [-1,1]

        noisy_images.append(noisy_image.reshape(96,96,1))

    return noisy_images



if random_noise_augmentation:

    noisy_train_images = add_noise(clean_train_images)

    print(f"Shape of noisy_train_images: {np.shape(noisy_train_images)}")

    train_images = np.concatenate((train_images, noisy_train_images))

    train_keypoints = np.concatenate((train_keypoints, clean_train_keypoints))

    fig, axis = plt.subplots()

    plot_sample(noisy_train_images[sample_image_index], clean_train_keypoints[sample_image_index], axis, "Random Noise Augmentation")
print("Shape of final train_images: {}".format(np.shape(train_images)))

print("Shape of final train_keypoints: {}".format(np.shape(train_keypoints)))



print("\n Clean Train Data: ")

fig = plt.figure(figsize=(20,8))

for i in range(10):

    axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])

    plot_sample(clean_train_images[i], clean_train_keypoints[i], axis, "")

plt.show()



if include_unclean_data:

    print("Unclean Train Data: ")

    fig = plt.figure(figsize=(20,8))

    for i in range(10):

        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])

        plot_sample(unclean_train_images[i], unclean_train_keypoints[i], axis, "")

    plt.show()



if horizontal_flip:

    print("Horizontal Flip Augmentation: ")

    fig = plt.figure(figsize=(20,8))

    for i in range(10):

        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])

        plot_sample(flipped_train_images[i], flipped_train_keypoints[i], axis, "")

    plt.show()



if rotation_augmentation:

    print("Rotation Augmentation: ")

    fig = plt.figure(figsize=(20,8))

    for i in range(10):

        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])

        plot_sample(rotated_train_images[i], rotated_train_keypoints[i], axis, "")

    plt.show()

    

if brightness_augmentation:

    print("Brightness Augmentation: ")

    fig = plt.figure(figsize=(20,8))

    for i in range(10):

        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])

        plot_sample(altered_brightness_train_images[i], altered_brightness_train_keypoints[i], axis, "")

    plt.show()



if shift_augmentation:

    print("Shift Augmentation: ")

    fig = plt.figure(figsize=(20,8))

    for i in range(10):

        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])

        plot_sample(shifted_train_images[i], shifted_train_keypoints[i], axis, "")

    plt.show()

    

if random_noise_augmentation:

    print("Random Noise Augmentation: ")

    fig = plt.figure(figsize=(20,8))

    for i in range(10):

        axis = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])

        plot_sample(noisy_train_images[i], clean_train_keypoints[i], axis, "")

    plt.show()
model = Sequential()



# Input dimensions: (None, 96, 96, 1)

model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

# Input dimensions: (None, 96, 96, 32)

model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

model.add(MaxPool2D(pool_size=(2, 2)))



# Input dimensions: (None, 48, 48, 32)

model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

# Input dimensions: (None, 48, 48, 64)

model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

model.add(MaxPool2D(pool_size=(2, 2)))



# Input dimensions: (None, 24, 24, 64)

model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

# Input dimensions: (None, 24, 24, 96)

model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

model.add(MaxPool2D(pool_size=(2, 2)))



# Input dimensions: (None, 12, 12, 96)

model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

# Input dimensions: (None, 12, 12, 128)

model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

model.add(MaxPool2D(pool_size=(2, 2)))



# Input dimensions: (None, 6, 6, 128)

model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

# Input dimensions: (None, 6, 6, 256)

model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

model.add(MaxPool2D(pool_size=(2, 2)))



# Input dimensions: (None, 3, 3, 256)

model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())

# Input dimensions: (None, 3, 3, 512)

model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))

model.add(LeakyReLU(alpha = 0.1))

model.add(BatchNormalization())



# Input dimensions: (None, 3, 3, 512)

model.add(Flatten())

model.add(Dense(512,activation='relu'))

model.add(Dropout(0.1))

model.add(Dense(30))

model.summary()



# Load a pre-trained model (if present)

if os.path.exists('../input/data-augmentation-for-facial-keypoint-detection/best_model.hdf5'):

    model = load_model('../input/data-augmentation-for-facial-keypoint-detection/best_model.hdf5')



# Define necessary callbacks

checkpointer = ModelCheckpoint(filepath = 'best_model.hdf5', monitor='val_mae', verbose=1, save_best_only=True, mode='min')



# Compile the model

model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc'])



# Train the model

history = model.fit(train_images, train_keypoints, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, validation_split=0.05, callbacks=[checkpointer])
# summarize history for mean_absolute_error

try:

    plt.plot(history.history['mae'])

    plt.plot(history.history['val_mae'])

    plt.title('Mean Absolute Error vs Epoch')

    plt.ylabel('Mean Absolute Error')

    plt.xlabel('Epochs')

    plt.legend(['train', 'validation'], loc='upper right')

    plt.show()

    # summarize history for accuracy

    plt.plot(history.history['acc'])

    plt.plot(history.history['val_acc'])

    plt.title('Accuracy vs Epoch')

    plt.ylabel('Accuracy')

    plt.xlabel('Epochs')

    plt.legend(['train', 'validation'], loc='upper left')

    plt.show()

    # summarize history for loss

    plt.plot(history.history['loss'])

    plt.plot(history.history['val_loss'])

    plt.title('Loss vs Epoch')

    plt.ylabel('Loss')

    plt.xlabel('Epochs')

    plt.legend(['train', 'validation'], loc='upper left')

    plt.show()

except:

    print("One of the metrics used for plotting graphs is missing! See 'model.compile()'s `metrics` argument.")
# %%time



# # Modify ModelCheckpoint callback to save model with best train mae to disk (instead of best validation mae)

# checkpointer = ModelCheckpoint(filepath = 'best_model.hdf5', monitor='mae', verbose=1, save_best_only=True, mode='min')

# model.fit(train_images, train_keypoints, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, callbacks=[checkpointer])

 

model = load_model('best_model.hdf5')

test_preds = model.predict(test_images)
fig = plt.figure(figsize=(20,16))

for i in range(20):

    axis = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])

    plot_sample(test_images[i], test_preds[i], axis, "")

plt.show()
feature_names = list(idlookup_data['FeatureName'])

image_ids = list(idlookup_data['ImageId']-1)

row_ids = list(idlookup_data['RowId'])



feature_list = []

for feature in feature_names:

    feature_list.append(feature_names.index(feature))

    

predictions = []

for x,y in zip(image_ids, feature_list):

    predictions.append(test_preds[x][y])

    

row_ids = pd.Series(row_ids, name = 'RowId')

locations = pd.Series(predictions, name = 'Location')

locations = locations.clip(0.0,96.0)

submission_result = pd.concat([row_ids,locations],axis = 1)

submission_result.to_csv('submission.csv',index = False)